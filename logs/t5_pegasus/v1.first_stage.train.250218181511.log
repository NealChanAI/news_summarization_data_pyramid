2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:50] 
2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:50] 
2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:50] 
2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:50] 
2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:50] 
2025-02-18 18:15:11,190	[INFO]	[algo_reco.train]	[log.py:51] ========== new log ==========
2025-02-18 18:15:11,190	[DEBUG]	[algo_reco.train]	[log.py:52] logfile is [D:\neal\develop\news_summarization_data_pyramid\logs\t5_pegasus\v1.first_stage.train.250218181511.log]
2025-02-18 18:15:11,191	[INFO]	[algo_reco.train]	[log.py:60] init logger done
2025-02-18 18:15:11,191	[INFO]	[algo_reco.train]	[log.py:61] 
2025-02-18 18:15:11,191	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:384] ===== input args =====
2025-02-18 18:15:11,191	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] train_data: D:\neal\develop\news_summarization_data_pyramid\data\THUCNews\companies_news_info_v2.train.txt
2025-02-18 18:15:11,191	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] dev_data: D:\neal\develop\news_summarization_data_pyramid\data\THUCNews\companies_news_info_v2.valid.txt
2025-02-18 18:15:11,191	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] pretrain_model: D:\neal\develop\news_summarization_data_pyramid\model\chinese_t5_pegasus_base_torch
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] model_dir: D:\neal\develop\news_summarization_data_pyramid\model\saved_model
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] model_specific_dir: t5_pegasus
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] num_epoch: 2
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] batch_size: 4
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] lr: 0.0002
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] data_parallel: False
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] max_len: 512
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] max_len_generate: 40
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] length_penalty: 1.2
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] version: v1
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:386] stage: first_stage
2025-02-18 18:15:11,192	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:387] 
2025-02-18 18:15:23,284	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.second_stage.test.py:315] Iter 0:  Training Loss: 23.852882385253906

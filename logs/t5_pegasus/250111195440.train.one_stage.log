2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:51] ========== new log ==========
2025-01-11 19:54:40,923	[DEBUG]	[algo_reco.train]	[log.py:52] logfile is [/root/develop/news_summarization_data_pyramid/logs/t5_pegasus/250111195440.train.one_stage.log]
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:60] init logger done
2025-01-11 19:54:40,923	[INFO]	[algo_reco.train]	[log.py:61] 
2025-01-11 19:54:40,923	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:309] ===== input args =====
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] train_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.train.txt
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] dev_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.test.txt
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] pretrain_model: /root/develop/news_summarization_data_pyramid/model/chinese_t5_pegasus_base_torch
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] model_dir: /root/develop/news_summarization_data_pyramid/model/saved_model
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] model_specific_dir: t5_pegasus
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] num_epoch: 20
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] batch_size: 4
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] lr: 0.0002
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] data_parallel: False
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] max_len: 1024
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] max_len_generate: 150
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] length_penalty: 1.2
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] stage: one_stage
2025-01-11 19:54:40,924	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:312] 
2025-01-11 19:55:31,915	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 0:  Training Loss: 31.512937545776367
2025-01-11 19:55:53,684	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 100:  Training Loss: 5.963283538818359
2025-01-11 19:56:16,417	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 200:  Training Loss: 4.844245910644531
2025-01-11 19:56:37,197	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 300:  Training Loss: 3.1571781635284424
2025-01-11 19:56:59,058	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 400:  Training Loss: 3.1732640266418457
2025-01-11 19:57:20,450	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 500:  Training Loss: 3.6137874126434326
2025-01-11 19:57:42,769	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 600:  Training Loss: 2.7457966804504395
2025-01-11 19:58:05,175	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 700:  Training Loss: 2.7643673419952393
2025-01-11 19:58:27,660	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 800:  Training Loss: 2.3803741931915283
2025-01-11 19:58:51,177	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 900:  Training Loss: 2.5099124908447266
2025-01-11 19:59:13,359	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1000:  Training Loss: 3.0442724227905273
2025-01-11 19:59:35,607	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1100:  Training Loss: 2.0114901065826416
2025-01-11 19:59:57,261	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1200:  Training Loss: 2.4527950286865234
2025-01-11 20:00:20,549	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1300:  Training Loss: 1.6529722213745117
2025-01-11 20:00:43,687	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1400:  Training Loss: 2.540659189224243
2025-01-11 20:01:05,005	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1500:  Training Loss: 1.905184030532837
2025-01-11 20:01:27,338	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1600:  Training Loss: 1.8261874914169312
2025-01-11 20:01:50,504	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1700:  Training Loss: 2.182861566543579
2025-01-11 20:02:12,736	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1800:  Training Loss: 2.28354811668396
2025-01-11 20:02:34,065	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1900:  Training Loss: 1.8115907907485962
2025-01-11 20:02:56,298	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2000:  Training Loss: 2.0472843647003174
2025-01-11 20:03:18,525	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2100:  Training Loss: 1.9029992818832397
2025-01-11 20:08:09,827	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:274] Validation Loss: {'rouge-1': 0.6413865407511499, 'rouge-2': 0.4581292744009655, 'rouge-l': 0.5634808743453015}
2025-01-11 20:08:11,212	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 0:  Training Loss: 1.4950623512268066
2025-01-11 20:08:33,077	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 100:  Training Loss: 1.886315107345581
2025-01-11 20:08:55,937	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 200:  Training Loss: 1.8972219228744507
2025-01-11 20:09:16,846	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 300:  Training Loss: 1.3091230392456055
2025-01-11 20:09:38,802	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 400:  Training Loss: 1.8336459398269653
2025-01-11 20:10:00,137	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 500:  Training Loss: 1.7412484884262085
2025-01-11 20:10:22,925	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 600:  Training Loss: 1.6510812044143677
2025-01-11 20:10:46,472	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 700:  Training Loss: 1.6112651824951172
2025-01-11 20:11:10,063	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 800:  Training Loss: 1.5059223175048828
2025-01-11 20:11:34,653	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 900:  Training Loss: 1.8829103708267212
2025-01-11 20:11:57,860	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1000:  Training Loss: 2.3250601291656494
2025-01-11 20:12:19,994	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1100:  Training Loss: 1.202585220336914
2025-01-11 20:12:41,566	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1200:  Training Loss: 1.5151596069335938
2025-01-11 20:13:04,750	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1300:  Training Loss: 1.4460796117782593
2025-01-11 20:13:27,804	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1400:  Training Loss: 1.6500321626663208
2025-01-11 20:13:48,989	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1500:  Training Loss: 1.5469090938568115
2025-01-11 20:14:11,192	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1600:  Training Loss: 1.2347314357757568
2025-01-11 20:14:34,244	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1700:  Training Loss: 1.6940995454788208
2025-01-11 20:14:56,341	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1800:  Training Loss: 1.5260926485061646
2025-01-11 20:15:17,515	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1900:  Training Loss: 1.7867939472198486
2025-01-11 20:15:39,596	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2000:  Training Loss: 1.183853030204773
2025-01-11 20:16:01,527	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2100:  Training Loss: 1.515098214149475
2025-01-11 20:21:02,814	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:274] Validation Loss: {'rouge-1': 0.643514233597877, 'rouge-2': 0.46044585360771023, 'rouge-l': 0.567574418232259}
2025-01-11 20:21:04,588	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 0:  Training Loss: 1.0073498487472534
2025-01-11 20:21:26,249	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 100:  Training Loss: 1.4084415435791016
2025-01-11 20:21:48,883	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 200:  Training Loss: 1.1202131509780884
2025-01-11 20:22:09,560	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 300:  Training Loss: 0.8863214254379272
2025-01-11 20:22:31,339	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 400:  Training Loss: 1.0585308074951172
2025-01-11 20:22:52,494	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 500:  Training Loss: 1.4276973009109497
2025-01-11 20:23:14,772	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 600:  Training Loss: 1.2789093255996704
2025-01-11 20:23:37,064	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 700:  Training Loss: 1.477849006652832
2025-01-11 20:23:59,486	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 800:  Training Loss: 1.243143916130066
2025-01-11 20:24:22,958	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 900:  Training Loss: 1.266916036605835
2025-01-11 20:24:45,071	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1000:  Training Loss: 1.6055058240890503
2025-01-11 20:25:07,241	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1100:  Training Loss: 0.8361544013023376
2025-01-11 20:25:28,782	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1200:  Training Loss: 1.080984354019165
2025-01-11 20:25:51,969	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1300:  Training Loss: 0.9895458221435547
2025-01-11 20:26:15,047	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1400:  Training Loss: 1.453493595123291
2025-01-11 20:26:36,297	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1500:  Training Loss: 1.163741946220398
2025-01-11 20:26:58,586	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1600:  Training Loss: 0.9333272576332092
2025-01-11 20:27:21,686	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1700:  Training Loss: 1.1899358034133911
2025-01-11 20:27:43,832	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1800:  Training Loss: 0.9747918248176575
2025-01-11 20:28:05,144	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1900:  Training Loss: 1.183593511581421
2025-01-11 20:28:27,243	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2000:  Training Loss: 0.7952162623405457
2025-01-11 20:28:49,191	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2100:  Training Loss: 1.1980749368667603
2025-01-11 20:33:43,599	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:274] Validation Loss: {'rouge-1': 0.6470948846401058, 'rouge-2': 0.46276047165448825, 'rouge-l': 0.5676362251354371}
2025-01-11 20:33:45,386	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 0:  Training Loss: 0.9610217809677124
2025-01-11 20:34:07,199	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 100:  Training Loss: 1.178411841392517
2025-01-11 20:34:29,998	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 200:  Training Loss: 1.1485872268676758
2025-01-11 20:34:50,914	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 300:  Training Loss: 0.7204396724700928
2025-01-11 20:35:12,900	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 400:  Training Loss: 0.8851057887077332
2025-01-11 20:35:34,231	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 500:  Training Loss: 1.0043922662734985
2025-01-11 20:35:56,596	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 600:  Training Loss: 0.9154916405677795
2025-01-11 20:36:19,031	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 700:  Training Loss: 1.1221829652786255
2025-01-11 20:36:41,605	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 800:  Training Loss: 0.7932469248771667
2025-01-11 20:37:05,151	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 900:  Training Loss: 0.875002920627594
2025-01-11 20:37:27,406	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1000:  Training Loss: 1.401611566543579
2025-01-11 20:37:49,701	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1100:  Training Loss: 0.8017902374267578
2025-01-11 20:38:11,414	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1200:  Training Loss: 0.5691443085670471
2025-01-11 20:38:34,729	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1300:  Training Loss: 0.7244417071342468
2025-01-11 20:38:57,890	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1400:  Training Loss: 0.8875837326049805
2025-01-11 20:39:19,227	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1500:  Training Loss: 0.8882700204849243
2025-01-11 20:39:41,610	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1600:  Training Loss: 0.8009976744651794
2025-01-11 20:40:04,810	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1700:  Training Loss: 1.0851832628250122
2025-01-11 20:40:27,100	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1800:  Training Loss: 0.6049641370773315
2025-01-11 20:40:48,490	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1900:  Training Loss: 0.7555124163627625
2025-01-11 20:41:10,778	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2000:  Training Loss: 0.7837282419204712
2025-01-11 20:41:32,893	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 2100:  Training Loss: 1.1167117357254028
2025-01-11 20:46:41,863	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:274] Validation Loss: {'rouge-1': 0.6556351320350374, 'rouge-2': 0.46685076486599575, 'rouge-l': 0.5727813775090113}
2025-01-11 20:46:43,645	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 0:  Training Loss: 0.8847055435180664
2025-01-11 20:47:05,391	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 100:  Training Loss: 0.9037811756134033
2025-01-11 20:47:28,126	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 200:  Training Loss: 0.7979913949966431
2025-01-11 20:47:48,884	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 300:  Training Loss: 0.5520956516265869
2025-01-11 20:48:10,705	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 400:  Training Loss: 0.6185691952705383
2025-01-11 20:48:31,958	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 500:  Training Loss: 0.8170629143714905
2025-01-11 20:48:54,355	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 600:  Training Loss: 0.541729211807251
2025-01-11 20:49:16,762	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 700:  Training Loss: 0.8972975015640259
2025-01-11 20:49:39,174	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 800:  Training Loss: 0.595154881477356
2025-01-11 20:50:02,644	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 900:  Training Loss: 0.7647477984428406
2025-01-11 20:50:24,766	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1000:  Training Loss: 1.0852447748184204
2025-01-11 20:50:46,952	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1100:  Training Loss: 0.3727123439311981
2025-01-11 20:51:08,577	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1200:  Training Loss: 0.7510373592376709
2025-01-11 20:51:31,793	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:244] Iter 1300:  Training Loss: 0.6127109527587891

2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:51] ========== new log ==========
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[log.py:52] logfile is [/root/develop/news_summarization_data_pyramid/logs/t5_pegasus/250111192643.train.one_stage.log]
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:60] init logger done
2025-01-11 19:26:43,115	[INFO]	[algo_reco.train]	[log.py:61] 
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:304] ===== input args =====
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] train_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.train.txt
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] dev_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.test.txt
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] pretrain_model: /root/develop/news_summarization_data_pyramid/model/chinese_t5_pegasus_base_torch
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] model_dir: /root/develop/news_summarization_data_pyramid/model/saved_model
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] model_specific_dir: t5_pegasus
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] num_epoch: 20
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] batch_size: 4
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] lr: 0.0002
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] data_parallel: False
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] max_len: 1024
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] max_len_generate: 150
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] length_penalty: 1.2
2025-01-11 19:26:43,115	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:306] stage: one_stage
2025-01-11 19:26:43,116	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:307] 
2025-01-11 19:27:42,293	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 0:  Training Loss: 32.063446044921875
2025-01-11 19:28:04,319	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 100:  Training Loss: 6.340554237365723
2025-01-11 19:28:27,306	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 200:  Training Loss: 4.337491989135742
2025-01-11 19:28:48,337	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 300:  Training Loss: 3.2935452461242676
2025-01-11 19:29:10,625	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 400:  Training Loss: 3.3523213863372803
2025-01-11 19:29:32,012	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 500:  Training Loss: 3.1003289222717285
2025-01-11 19:29:54,445	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 600:  Training Loss: 3.5252742767333984
2025-01-11 19:30:17,091	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 700:  Training Loss: 3.4435036182403564
2025-01-11 19:30:39,789	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 800:  Training Loss: 2.6696183681488037
2025-01-11 19:31:03,360	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 900:  Training Loss: 3.2552735805511475
2025-01-11 19:31:25,859	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1000:  Training Loss: 3.091496467590332
2025-01-11 19:31:48,437	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1100:  Training Loss: 1.891188383102417
2025-01-11 19:32:10,770	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1200:  Training Loss: 2.500150680541992
2025-01-11 19:32:34,435	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1300:  Training Loss: 1.9089146852493286
2025-01-11 19:32:57,580	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1400:  Training Loss: 2.6617352962493896
2025-01-11 19:33:18,905	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1500:  Training Loss: 2.127957344055176
2025-01-11 19:33:41,270	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1600:  Training Loss: 1.9257891178131104
2025-01-11 19:34:04,438	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1700:  Training Loss: 2.554138422012329
2025-01-11 19:34:26,687	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1800:  Training Loss: 2.0585262775421143
2025-01-11 19:34:48,028	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 1900:  Training Loss: 1.9858736991882324
2025-01-11 19:35:10,238	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 2000:  Training Loss: 1.5564701557159424
2025-01-11 19:35:32,239	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 2100:  Training Loss: 2.113098382949829
2025-01-11 19:40:30,462	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:269] Validation Loss: {'rouge-1': 0.6346475548374565, 'rouge-2': 0.4497515426153631, 'rouge-l': 0.5592878043014434}

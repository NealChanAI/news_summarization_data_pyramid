2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:51] ========== new log ==========
2025-01-21 14:25:36,729	[DEBUG]	[algo_reco.train]	[log.py:52] logfile is [/root/news_summarization_data_pyramid/logs/t5_pegasus/v1.one_stage.train.250121142536.log]
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:60] init logger done
2025-01-21 14:25:36,729	[INFO]	[algo_reco.train]	[log.py:61] 
2025-01-21 14:25:36,729	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:308] ===== input args =====
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] train_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.train.txt
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] dev_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.test.txt
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] pretrain_model: /root/news_summarization_data_pyramid/model/chinese_t5_pegasus_base_torch
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] model_dir: /root/news_summarization_data_pyramid/model/saved_model
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] model_specific_dir: t5_pegasus
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] num_epoch: 20
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] batch_size: 4
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] lr: 0.0002
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] data_parallel: False
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] max_len: 1024
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] max_len_generate: 150
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] length_penalty: 1.2
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] version: v1
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:310] stage: one_stage
2025-01-21 14:25:36,730	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:311] 
2025-01-21 14:26:27,121	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:242] Iter 0:  Training Loss: 29.8818359375
2025-01-21 14:26:48,876	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:242] Iter 100:  Training Loss: 6.176333904266357

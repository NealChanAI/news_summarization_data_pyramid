2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:50] 
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:51] ========== new log ==========
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[log.py:52] logfile is [/root/develop/news_summarization_data_pyramid/logs/t5_pegasus/250111173105.train.log]
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:60] init logger done
2025-01-11 17:31:05,576	[INFO]	[algo_reco.train]	[log.py:61] 
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:300] ===== input args =====
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] train_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.train.txt
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] dev_data: data/THUCNews/abstractive_pseudo_summary_datasets_zhipu.test.txt
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] pretrain_model: /root/develop/news_summarization_data_pyramid/model/chinese_t5_pegasus_base_torch
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] model_dir: /root/develop/news_summarization_data_pyramid/model/saved_model
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] model_specific_dir: t5_pegasus
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] num_epoch: 20
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] batch_size: 8
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] lr: 0.0002
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] data_parallel: False
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] max_len: 512
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:302] max_len_generate: 40
2025-01-11 17:31:05,576	[DEBUG]	[algo_reco.train]	[t5_pegasus_finetune.py:303] 
2025-01-11 17:31:54,046	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 0:  Training Loss: 1.3266351222991943
2025-01-11 17:32:22,033	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 100:  Training Loss: 1.4825736284255981
2025-01-11 17:32:50,082	[INFO]	[algo_reco.train]	[t5_pegasus_finetune.py:239] Iter 200:  Training Loss: 1.2045537233352661
